{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4ad6b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math \n",
    "import numpy as np \n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e47ae039",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size,embed_dim):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.voacab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "        nn.init.normal_(self.embedding.weight,mean=0.0,std=0.02)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x) * math.sqrt(self.embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4f4ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, max_seq_len,embed_dim):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.embed_dim = embed_dim\n",
    "        self.positional_embedding = nn.Embedding(max_seq_len, embed_dim)\n",
    "\n",
    "        nn.init.normal_(self.positional_embedding.weight,mean=0.0,std=0.02)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size,seq_len = x.shape[0],x.shape[1]\n",
    "        positions = torch.arange(seq_len, device=x.device).unsqueeze(0).expand(batch_size, -1)\n",
    "        return self.positional_embedding(positions) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6480a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPositionalEmbedding(nn.Module):\n",
    "    def __init__(self, max_seq_len,embed_dim):\n",
    "        super(SinusoidalPositionalEmbedding, self).__init__()\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        pe = torch.zeros(max_seq_len, embed_dim)\n",
    "        position = torch.arange(0,max_seq_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0,embed_dim,2).float()* - (math.log(10000.0)/embed_dim))\n",
    "        pe[:,0::2] = torch.sin(position*div_term)\n",
    "        pe[:,1::2] = torch.cos(position*div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self,x):\n",
    "        batch_size,seq_len =x.shape[0],x.shape[1]\n",
    "        return self.pe[:seq_len].unsqueeze(0).expand(batch_size, -1, -1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18961fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTEmbedding(nn.Module):\n",
    "    def __init__(self,vocab_size,embed_dim,max_seq_len,dropout=0.1,use_sinusoidal= False):\n",
    "        super(GPTEmbedding, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "        self.token_embedding = TokenEmbedding(vocab_size, embed_dim)\n",
    "        if use_sinusoidal:\n",
    "            self.pos_embedding = SinusoidalPositionalEmbedding(max_seq_len, embed_dim)\n",
    "        else:\n",
    "            self.pos_embedding = PositionalEmbedding(max_seq_len, embed_dim)\n",
    "\n",
    "        #dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        #layer norm \n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "    \n",
    "    def forward(self,input_ids,use_layer_norm = True):\n",
    "        #token embedding\n",
    "        token_embedding = self.token_embedding(input_ids)\n",
    "        #positional embedding\n",
    "        pos_embedding = self.pos_embedding(token_embedding)\n",
    "        #add two embedding together\n",
    "        embedding = token_embedding + pos_embedding\n",
    "        #apply layer normalization \n",
    "        if use_layer_norm:\n",
    "            embedding = self.layer_norm(embedding)\n",
    "        #apply dropout\n",
    "        embedding = self.dropout(embedding)\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36ee319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTEmbeddingConfig:\n",
    "    def __init__(self, vocab_size=50257, embed_dim=768, max_seq_len=1024, \n",
    "                 dropout=0.1, use_sinusoidal=False):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.dropout = dropout\n",
    "        self.use_sinusoidal = use_sinusoidal\n",
    "\n",
    "def create_gpt_embedding(config):\n",
    "    return GPTEmbedding(\n",
    "        vocab_size=config.vocab_size,\n",
    "        embed_dim=config.embed_dim,\n",
    "        max_seq_len=config.max_seq_len,\n",
    "        dropout=config.dropout,\n",
    "        use_sinusoidal=config.use_sinusoidal\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "708f119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GPTEmbeddingConfig(\n",
    "    vocab_size=50257,  # GPT-2 vocabulary size\n",
    "    embed_dim=768,     # GPT-2 small embedding dimension\n",
    "    max_seq_len=1024,  # Maximum sequence length\n",
    "    dropout=0.1,       # Dropout rate\n",
    "    use_sinusoidal=False  # Use learned positional embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad137914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding layer\n",
    "embedding_layer = create_gpt_embedding(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "388159eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "seq_len = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fa12e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.randint(0, config.vocab_size, (batch_size, seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad19649d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 10])\n",
      "Input IDs: tensor([[ 9161, 40352, 37484, 49249, 42287, 48920, 41276, 36679, 39219,  3621],\n",
      "        [24871, 44604, 27175, 18944,  9701, 29295, 12688, 50128, 20299, 47859]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input shape: {input_ids.shape}\")\n",
    "print(f\"Input IDs: {input_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edc6a66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embedding_layer(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ef5b8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0000, -0.9064,  1.4496,  ..., -0.4646, -0.0521,  0.1483],\n",
       "         [ 0.3806,  0.1493, -0.5608,  ...,  2.6209, -2.1414,  0.9669],\n",
       "         [ 0.5841, -2.0113,  0.3768,  ..., -0.5104, -1.9701,  0.1873],\n",
       "         ...,\n",
       "         [-0.3686,  0.6418,  0.0000,  ...,  1.4214, -0.0256, -0.3128],\n",
       "         [ 0.7905, -1.2990,  0.2506,  ...,  0.0000,  0.6091, -1.0938],\n",
       "         [ 0.2463,  0.6668, -1.2025,  ..., -0.4090, -1.7647, -0.9470]],\n",
       "\n",
       "        [[ 1.0331, -1.1924,  1.3248,  ..., -0.7028,  0.6387, -1.9860],\n",
       "         [ 0.8715,  1.5800, -1.0191,  ...,  0.5569,  0.1109,  2.1714],\n",
       "         [-0.0000,  1.0864,  2.6517,  ...,  0.4587, -0.3082, -1.5197],\n",
       "         ...,\n",
       "         [-0.6633,  0.0000,  1.7616,  ...,  0.7605,  0.0335, -2.8521],\n",
       "         [-1.5386, -0.4770, -0.1424,  ...,  0.0578, -0.7824,  1.3027],\n",
       "         [-1.7761,  0.8889, -1.9276,  ..., -0.3346, -1.0794,  0.4307]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ee0709d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output embeddings shape: torch.Size([2, 10, 768])\n",
      "Expected shape: (2, 10, 768)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Output embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Expected shape: ({batch_size}, {seq_len}, {config.embed_dim})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a87b9362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output with layer norm shape: torch.Size([2, 10, 768])\n"
     ]
    }
   ],
   "source": [
    "embeddings_with_ln = embedding_layer(input_ids, use_layer_norm=True)\n",
    "print(f\"Output with layer norm shape: {embeddings_with_ln.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c63eb640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embeddings shape: torch.Size([2, 10, 768])\n"
     ]
    }
   ],
   "source": [
    "token_emb = embedding_layer.token_embedding(input_ids)\n",
    "print(f\"Token embeddings shape: {token_emb.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a296f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional embeddings shape: torch.Size([2, 10, 768])\n"
     ]
    }
   ],
   "source": [
    "pos_emb = embedding_layer.pos_embedding(token_emb)\n",
    "print(f\"Positional embeddings shape: {pos_emb.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "167afc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sinusoidal embeddings shape: torch.Size([2, 10, 768])\n"
     ]
    }
   ],
   "source": [
    "config_sin = GPTEmbeddingConfig(use_sinusoidal=True)\n",
    "embedding_layer_sin = create_gpt_embedding(config_sin)\n",
    "embeddings_sin = embedding_layer_sin(input_ids)\n",
    "print(f\"Sinusoidal embeddings shape: {embeddings_sin.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c438ef7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total parameters in embedding layer: 39,385,344\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in embedding_layer.parameters())\n",
    "print(f\"\\nTotal parameters in embedding layer: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a115779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_params = embedding_layer.token_embedding.embedding.weight.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "739d663a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38597376"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "898772f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "786432"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_params = embedding_layer.pos_embedding.positional_embedding.weight.numel()\n",
    "pos_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e124a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln_params = sum(p.numel() for p in embedding_layer.layer_norm.parameters())\n",
    "ln_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2629b2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding parameters: 38,597,376\n",
      "Positional embedding parameters: 786,432\n",
      "Layer norm parameters: 1,536\n"
     ]
    }
   ],
   "source": [
    "print(f\"Token embedding parameters: {token_params:,}\")\n",
    "print(f\"Positional embedding parameters: {pos_params:,}\")\n",
    "print(f\"Layer norm parameters: {ln_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48511578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing gradient flow \n",
    "embeddings.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85e8e505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embedding statistics:\n",
      "Mean: -0.0033\n",
      "Std: 1.0500\n",
      "Min: -4.0809\n",
      "Max: 4.1776\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nEmbedding statistics:\")\n",
    "print(f\"Mean: {embeddings.mean().item():.4f}\")\n",
    "print(f\"Std: {embeddings.std().item():.4f}\")\n",
    "print(f\"Min: {embeddings.min().item():.4f}\")\n",
    "print(f\"Max: {embeddings.max().item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b491f3f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
